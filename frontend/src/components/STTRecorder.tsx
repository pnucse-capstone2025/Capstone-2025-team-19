"use client";

import { useEffect, useRef, useState } from "react";
import { useAnnotation } from "./AnnotationContext";
import Image from "next/image";
import PLAY from "@/components/image/play.svg";
import STOP from "@/components/image/stop.svg";

type STTRecorderProps = {
  fileId?: string | number | null;
  isPdfReady?: boolean;
};

export default function STTRecorder({ fileId, isPdfReady = false }: STTRecorderProps) {
  const { addAnnotation } = useAnnotation();
  const [socket, setSocket] = useState<WebSocket | null>(null);
  const [isRecording, setIsRecording] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0); // ì´ˆ ë‹¨ìœ„ ì‹œê°„
  const API_WSS_URL = process.env.NEXT_PUBLIC_API_WSS_URL;

  const intervalRef = useRef<NodeJS.Timeout | null>(null);
  const keepAliveIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const processorRef = useRef<ScriptProcessorNode | null>(null);
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const fileIdRef = useRef<typeof fileId>(fileId);
  const hasSentFirstAudioRef = useRef<boolean>(false);
  useEffect(() => { fileIdRef.current = fileId; }, [fileId]);
  const formatTime = (seconds: number) => {
    const mins = String(Math.floor(seconds / 60)).padStart(2, "0");
    const secs = String(seconds % 60).padStart(2, "0");
    return `00:${mins}:${secs}`;
  };

  const convertFloat32ToInt16 = (buffer: Float32Array) => {
    const l = buffer.length;
    const result = new Int16Array(l);
    for (let i = 0; i < l; i++) {
      const s = Math.max(-1, Math.min(1, buffer[i]));
      result[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
      result[i] = Math.floor(result[i]);
    }
    return result;
  };

  const startRecording = async () => {
    try {
      // PDF ì¤€ë¹„ ìƒíƒœ ì²´í¬
      if (!isPdfReady) {
        alert("PDF ë¶„ì„ì´ ëë‚˜ê³  ë…¹ìŒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì¡°ê¸ˆë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.");
        return;
      }
      
      // 1. WebSocket ì¸ì¦ í† í° ë°œê¸‰ (ë¡œê·¸ì¸í•œ ì‚¬ìš©ìë§Œ)
      let connectionToken: string | null = null;
      try {
        const { auth } = await import("@/lib/auth");
        const token = auth.getAccessToken();
        
        if (token) {
          // ë¡œê·¸ì¸í•œ ì‚¬ìš©ì: ì¸ì¦ í† í° ë°œê¸‰
          const authResponse = await fetch(`${process.env.NEXT_PUBLIC_API_BASE_URL || 'http://localhost:8080'}/api/websocket/auth`, {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${token}`,
              'Content-Type': 'application/json'
            }
          });

          if (authResponse.ok) {
            const authData = await authResponse.json();
            connectionToken = authData.connectionToken;
            console.log("ğŸ”‘ [WebSocket] ì¸ì¦ ì„±ê³µ, connectionToken ë°œê¸‰ë¨");
          } else {
            console.warn("âš ï¸ [WebSocket] ì¸ì¦ ì‹¤íŒ¨, ë¡œê·¸ì¸í•˜ì§€ ì•Šì€ ì‚¬ìš©ìë¡œ ì§„í–‰");
          }
        } else {
          console.log("â„¹ï¸ [WebSocket] ë¡œê·¸ì¸í•˜ì§€ ì•Šì€ ì‚¬ìš©ì, ì¸ì¦ ì—†ì´ ì§„í–‰");
        }
      } catch (e) {
        console.warn("âš ï¸ [WebSocket] ì¸ì¦ ì‹¤íŒ¨, ë¡œê·¸ì¸í•˜ì§€ ì•Šì€ ì‚¬ìš©ìë¡œ ì§„í–‰:", e);
      }

      // 2. WebSocket ì—°ê²°
      const url = new URL(process.env.NEXT_PUBLIC_API_WSS_URL || 'ws://localhost:8080/ws/audio');
      // fileIdê°€ ìˆìœ¼ë©´ ì¿¼ë¦¬ì— í¬í•¨, ì—†ìœ¼ë©´ ìƒëµí•˜ì—¬ STTë§Œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
      if (fileIdRef.current !== undefined && fileIdRef.current !== null && String(fileIdRef.current) !== "") {
        url.searchParams.set("fileId", String(fileIdRef.current));
      }
      // connectionTokenì„ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¡œ ì¶”ê°€
      if (connectionToken) {
        url.searchParams.set("token", connectionToken);
      }
      
      const ws = new WebSocket(url.toString());
      setSocket(ws);

      ws.onopen = async () => {
        console.log("ğŸ”— [WebSocket] ì—°ê²° ì„±ê³µ");
        // ë¬´ìŒ keep-alive ì‹œì‘ (ë§ˆì´í¬ ì¤€ë¹„ ì „ íƒ€ì„ì•„ì›ƒ ë°©ì§€)
        if (!keepAliveIntervalRef.current) {
          keepAliveIntervalRef.current = setInterval(() => {
            if (ws.readyState === WebSocket.OPEN && !hasSentFirstAudioRef.current) {
              const silentFrame = new Int16Array(1600); // ì•½ 100ms @ 16kHz
              ws.send(silentFrame.buffer);
            }
          }, 200); // 200ms ê°„ê²©
        }
        if (typeof navigator === "undefined" || !navigator.mediaDevices?.getUserMedia) {
          alert("í˜„ì¬ ë¸Œë¼ìš°ì €ê°€ ë§ˆì´í¬ ê¶Œí•œì„ ì§€ì›í•˜ì§€ ì•Šê±°ë‚˜ ì˜ëª»ëœ í™˜ê²½ì…ë‹ˆë‹¤.");
          return;
        }
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          streamRef.current = stream;

          const audioContext = new AudioContext({ sampleRate: 16000 }); // ìµœì ì˜ íŒŒë¼ë¯¸í„° (16kHz)
          audioContextRef.current = audioContext;

          const source = audioContext.createMediaStreamSource(stream);
          sourceRef.current = source;

          const processor = audioContext.createScriptProcessor(4096, 1, 1); // ìµœì ì˜ íŒŒë¼ë¯¸í„° (4096 ìƒ˜í”Œ)
          processorRef.current = processor;

          source.connect(processor);
          processor.connect(audioContext.destination);

          processor.onaudioprocess = (e) => {
            const input = e.inputBuffer.getChannelData(0);
            const pcm = convertFloat32ToInt16(input);
            if (ws.readyState === WebSocket.OPEN) {
              // ì²« ì‹¤ì œ ì˜¤ë””ì˜¤ í”„ë ˆì„ ì „ì†¡ ì‹œ keep-alive ì¤‘ì§€
              if (!hasSentFirstAudioRef.current) {
                hasSentFirstAudioRef.current = true;
                if (keepAliveIntervalRef.current) {
                  clearInterval(keepAliveIntervalRef.current);
                  keepAliveIntervalRef.current = null;
                }
              }
              ws.send(pcm.buffer);
              // fileId ì—†ì´ë„ ë™ì‘í•˜ë„ë¡ init ë©”ì‹œì§€ëŠ” ì„ íƒì ìœ¼ë¡œë§Œ ì „ì†¡
              if (fileIdRef.current !== undefined && fileIdRef.current !== null && String(fileIdRef.current) !== "") {
                ws.send(JSON.stringify({ type: "init", fileId: fileIdRef.current }));
              }
            }
          };
        } catch (err) {
          console.error("ë¡œê·¸ì¸ ì˜¤ë¥˜:", err);
          alert("ë¡œê·¸ì¸ì„ í•˜ì…”ì•¼ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.");
        }

        setIsRecording(true);
        setRecordingTime(0);
        intervalRef.current = setInterval(() => {
          setRecordingTime((prev) => prev + 1);
        }, 1000);
      };

      ws.onmessage = (event) => {
        const parsed = JSON.parse(event.data);
        addAnnotation({
          id: crypto.randomUUID(),
          text: event.data,
          markdown: null,
          answerState: parsed.answerState ?? 1,
          pageNumber: parsed.page, 
        });
        window.dispatchEvent(new Event("annotation-added"));

      };

      ws.onerror = (err) => {
        console.error("âŒ [WebSocket] ì—°ê²° ì˜¤ë¥˜:", err);
        console.error("âŒ [WebSocket] URL:", url.toString());
        alert("WebSocket ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.");
      };

      ws.onclose = (event) => {
        console.log("ğŸ”Œ [WebSocket] ì—°ê²° ì¢…ë£Œ:", event.code, event.reason);
        if (event.code !== 1000) { // ì •ìƒ ì¢…ë£Œê°€ ì•„ë‹Œ ê²½ìš°
          alert(`ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (ì½”ë“œ: ${event.code})`);
        }
        stopRecordingInternal();
        setSocket(null);
      };
    } catch (err) {
      console.error("âŒ [STT] ì‹œì‘ ì‹¤íŒ¨:", err);
      alert("ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•˜ê±°ë‚˜ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
    }
  };

  const stopRecordingInternal = () => {
    processorRef.current?.disconnect();
    sourceRef.current?.disconnect();
    audioContextRef.current?.close();
    streamRef.current?.getTracks().forEach((track) => track.stop());

    processorRef.current = null;
    sourceRef.current = null;
    audioContextRef.current = null;
    streamRef.current = null;
    hasSentFirstAudioRef.current = false;

    clearInterval(intervalRef.current!);
    intervalRef.current = null;
    if (keepAliveIntervalRef.current) {
      clearInterval(keepAliveIntervalRef.current);
      keepAliveIntervalRef.current = null;
    }
    setIsRecording(false);
  };

  const stopRecording = () => {
    if (socket?.readyState === WebSocket.OPEN) {
      socket.close();
    } else {
      stopRecordingInternal();
      setSocket(null);
    }
  };

  return (
    <div className="flex items-center gap-4">
      {isRecording ? (
        <>
          {/* ë…¹ìŒ ì¤‘ - ì‹œê°„ í‘œì‹œ */}
          <div className="flex items-center gap-2 px-4 py-1 rounded-full bg-[#e8f0fe] text-[#1a2b49] text-sm font-medium">
            <div className="w-2 h-2 rounded-full bg-red-500 animate-pulse"></div>
            <span>ë…¹ìŒ ì¤‘ - {formatTime(recordingTime)}</span>
          </div>
          {/* ë…¹ìŒ ì¤‘ì§€ ë²„íŠ¼ */}
          <button
            className="flex items-center gap-2 px-4 py-2 rounded-full border border-gray-400 text-gray-800 text-sm bg-white"
            onClick={stopRecording}
          >
            <Image src={STOP} alt="Stop" width={14} height={14} />
            <span>ë…¹ìŒ ì¤‘ì§€</span>
          </button>
        </>
      ) : (
          <button
            className="flex items-center gap-2 px-4 py-2 rounded-full border border-gray-400 text-gray-800 text-sm bg-white hover:bg-gray-50"
            onClick={startRecording}
          >
          <Image src={PLAY} alt="Play" width={14} height={14} />
          <span className="text-gray-700 text-sm">ë…¹ìŒ ì‹œì‘</span>
        </button>
      )}
    </div>
  );
}
